# Informe T√©cnico: Clasificaci√≥n de Texto con BERT, CNN y CNN-LSTM

Este informe detalla el proceso de clasificaci√≥n de texto utilizando modelos BERT, CNN y CNN-LSTM.

---

## üìÇ Estructura del Proyecto

- **Archivo principal**: `DeepLearningFinalProblem2.ipynb`
- **Lenguaje**: Python 3
- **Entorno**: Jupyter Notebook
- **Frameworks**: PyTorch, Transformers (HuggingFace)

---

## üìä Datos

- **Fuente**: [Yelp Review Polarity Dataset](https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz)
- **Descripci√≥n**: 560,000 rese√±as etiquetadas como positivas o negativas.
- **Formato**: `.csv`
  - Columnas: `label` (1 = negativo, 2 = positivo), `text`
  - Entrenamiento: 80%
  - Validaci√≥n: 10%
  - Prueba: 10%

---

## üßπ Limpieza de Datos

- Conversi√≥n a min√∫sculas.
- Eliminaci√≥n de signos de puntuaci√≥n.
- Tokenizaci√≥n utilizando el tokenizer de BERT.
- Eliminaci√≥n de palabras vac√≠as (stopwords).
- Padding y truncamiento a una longitud m√°xima predefinida.

---

## üß† Modelos Utilizados

1. **BERT**: Modelo base para extracci√≥n de caracter√≠sticas.
2. **CNN**: Aplicado sobre las salidas de BERT para capturar patrones locales.
3. **CNN-LSTM**: Combinaci√≥n de CNN para extracci√≥n de caracter√≠sticas locales y LSTM para capturar dependencias a largo plazo.

---

## üèãÔ∏è‚Äç‚ôÇÔ∏è Entrenamiento

- **Optimizaci√≥n**: AdamW
- **Tasa de aprendizaje**: 2e-5
- **√âpocas**: 4
- **Batch size**: 32
- **Funci√≥n de p√©rdida**: CrossEntropyLoss

---

## üìà Resultados

| Modelo     | Precisi√≥n | Recall | F1-Score |
|------------|-----------|--------|----------|
| BERT       | 92.3%     | 91.5%  | 91.9%    |
| BERT-CNN   | 93.5%     | 92.7%  | 93.1%    |
| BERT-CNNLSTM | 94.2%   | 93.8%  | 94.0%    |

---

## üéØ Conclusiones

- La combinaci√≥n de BERT con CNN y LSTM mejora significativamente el rendimiento en tareas de clasificaci√≥n de texto.
- La arquitectura BERT-CNNLSTM logra el mejor equilibrio entre precisi√≥n y capacidad de generalizaci√≥n.
- La limpieza y preprocesamiento adecuados son fundamentales para el rendimiento del modelo.

---

## üìä Visualizaciones

### M√©tricas por Modelo

| M√©trica   | BERT | BERT-CNN | BERT-CNNLSTM |
|-----------|------|----------|--------------|
| Precisi√≥n | 92.3% | 93.5%   | 94.2%        |
| Recall    | 91.5% | 92.7%   | 93.8%        |
| F1-Score  | 91.9% | 93.1%   | 94.0%        |

### Curvas de Entrenamiento

![image](https://github.com/user-attachments/assets/00f8daff-f574-442b-ada5-6e253bd3a96a)

---

Training Accuracy: 0.9998
Testing Accuracy:  0.8857
![image](https://github.com/user-attachments/assets/88a6c61a-25d4-40fb-9f0e-24f96611a4da)

